{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14872,"status":"ok","timestamp":1722030622652,"user":{"displayName":"Lauren Pryor","userId":"00729258638441906783"},"user_tz":420},"id":"ne2UgkIbBGhV","outputId":"9ac734da-4caf-462a-8756-91c18c0bca70"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":802,"status":"ok","timestamp":1722030678329,"user":{"displayName":"Lauren Pryor","userId":"00729258638441906783"},"user_tz":420},"id":"RR8N0-cTBB1n","outputId":"f1416233-92b2-49be-e06d-3afccc15e1b1"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","from nltk.tokenize import sent_tokenize\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgeHNQvKA_MU"},"outputs":[],"source":["import pandas as pd\n","\n","# Define the path to your CSV file in Google Drive\n","input_file_path = '/content/drive/My Drive/metaU/pb_randomized_transformed_REAL.csv'\n","output_file_path = '/content/drive/My Drive/metaU/pb_by_sentence.csv'\n","\n","# Read the original CSV file\n","df = pd.read_csv(input_file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0d4BOscmBV5U"},"outputs":[],"source":["new_rows = []\n","\n","for _, row in df.iterrows():\n","    paragraphs = row['statement']\n","    left_leaning = row['left-leaning']\n","    right_leaning = row['right-leaning']\n","    neutral = row['neutral']\n","\n","    sentences = sent_tokenize(paragraphs)\n","\n","    for sentence in sentences:\n","        new_rows.append({\n","            'statement': sentence,\n","            'left-leaning': left_leaning,\n","            'right-leaning': right_leaning,\n","            'neutral': neutral\n","        })\n","\n","# Create a new DataFrame with the sentences and original columns\n","new_df = pd.DataFrame(new_rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otZvON0mCT8p"},"outputs":[],"source":["new_df.to_csv(output_file_path, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":175,"status":"ok","timestamp":1722030865971,"user":{"displayName":"Lauren Pryor","userId":"00729258638441906783"},"user_tz":420},"id":"NAI8QLsbBqly","outputId":"9415f169-4c6d-445c-cffc-438cb5bc1e43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shuffled CSV saved as /content/drive/My Drive/metaU/pb_by_sentence.csv\n"]}],"source":["print(f'Shuffled CSV saved as {output_file_path}')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPwtPQTJThqGmtgkPuvTmDk","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
